# Agent-Extraction-V2 Context

## Project Overview
Agent-Extraction-V2 is a document processing application designed to extract, parse, and structure information from PDF and TIFF files. The application runs as a console program that accepts the document file path as a parameter and outputs structured data ready for import into target systems.

## Architecture
The system is built in .NET and follows a pipeline architecture composed of three workers: Preparation, Extraction, and Parsing. These workers communicate through message queues using RabbitMQ, where each message includes a CorrelationId.

The system follows a three-phase pipeline architecture:

1. **PREPARATION**: 
   - Document pre-processing, conversion to JPG image files
   - Transform document into a collection of single page JPG files
   - OCR processing to extract text from images
   - Output: JPG files and extracted text

2. **EXTRACTION**: 
   - Additional data extraction from the processed document and JPG files
   - Uses LLM (Large Language Model) for intelligent extraction
   - Improves text recognition through OpenAI services
   - Output: Structured extracted text in JSON format

3. **PARSING**: 
   - Structuring and formatting the relevant extracted data for target systems
   - Analyzes which document type is being processed
   - Parses extracted data to build documents according to specifications
   - Output: Final structured document with key-value pairs and confidence levels

## Technical Details
- **Platform**: .NET 9
- **Language**: C#
- **Application Type**: Console application
- **Input**: Full file path to PDF or TIFF document
- **Output**: A folder configurable on a per-file basis

## Dependencies
All external dependencies must run in local containers, with the sole exception of OpenAI, which may be accessed as a cloud service. This includes:
- OCR services
- PDF to JPG conversion tools
- RabbitMQ for message queues
- Grafana and Loki for logging and monitoring
- Any other third-party processing tools

## Development Principles
- **Human-in-the-Loop**: All suggested changes require confirmation before implementation
- **Testing Focus**: Priority on tests over sample files in /samples directory
- **Logging**: Detailed logs for each phase of the pipeline
- **Containerization**: Local container-based deployment for all dependencies
- **Observability**: Grafana and Loki are integrated across the pipeline for logging and monitoring

## Workflow
1. Document is received as input parameter.
2. A CorrelationId (GUID) is generated, and a folder with this same value as its name is created.
3. The original file is copied into the new folder and renamed following the format `[CorrelationId]_original.pdf` or `[CorrelationId]_original.tiff`.
4. JPG files are generated for each page in the document following the format `[CorrelationId]_preparation_[n].jpg`.
5. For each page image, text is extracted using OCR library and stored in `[CorrelationId]_preparation_ocr_[n].json`.
6. When a new message arrives in the queue, the JPG images and extracted text are retrieved from storage.
7. Images and text are sent to OpenAI with a specific extraction prompt.
8. The text extracted by the LLM is saved in storage with the filename format `[CorrelationId]_extraction.json`.    
9. The final extracted text is retrieved from storage and sent to OpenAI for parsing.
10. The parsed result is saved in storage as `[CorrelationId]_parsing_result.json` with key-value pairs and confidence levels.
11. Output is generated in the configured format and location.

## Storage
The output generated by each worker is stored in a storage component that is agnostic to the underlying implementation. In the initial stage, the storage is file-based (using the folder created in step 2 described above), but it can be extended to other storage types.

## File Naming Convention
- Original renamed file: `[CorrelationId]_original.pdf` or `[CorrelationId]_original.tiff`
- Preparation phase JPG files: `[CorrelationId]_preparation_[n].jpg`
- Preparation phase OCR results: `[CorrelationId]_preparation_ocr_[n].json`
- Extraction phase results: `[CorrelationId]_extraction.json`
- Parsing phase results: `[CorrelationId]_parsing_result.json`

## Configuration
The system supports configuration options for:
- Output directory and format on a per-file basis
- Processing parameters
- Extraction rules
- OpenAI prompts for extraction and parsing phases
